No, the code I gave you is more complicated than what you need. Let me simplify.
You want a summary table like:
MNE
CLIENT_COUNT
TOTAL_TIMES_TARGETED
VCN
5,000
12,000
VDA
3,200
8,500
ABC
1,500
2,000
...
...
...
Where:
CLIENT_COUNT = unique clients from your list targeted by that campaign
TOTAL_TIMES_TARGETED = total records (includes repeat targeting)
Here's the simple version:
# %% Cell: Read Campaign Data
from pyspark.sql import functions as F

years = ["2024", "2025"]
paths = [f"/prod/sz/tsz/00150/cc/DTZTA_T_TACTIC_EVNT_HIST/EVNT_STRT_DT={year}*" for year in years]

tactic = spark.read.option("basePath", "/prod/sz/tsz/00150/cc/DTZTA_T_TACTIC_EVNT_HIST/") \
    .parquet(*paths) \
    .withColumn("MNE", F.substring(F.col("TACTIC_ID"), 8, 3)) \
    .withColumn("CLNT_NO", F.regexp_replace(F.trim(F.col("TACTIC_EVNT_ID")), "^0+", "")) \
    .select("CLNT_NO", "MNE")

print(f"Total tactic records: {tactic.count()}")


# %% Cell: Join with Client List
client_list = spark.read.csv(
    "/user/427966379/VVD_SRF_LIST.csv",
    header=True
).select("CLNT_NO").distinct()

# Keep only records for our clients
client_campaigns = tactic.join(broadcast(client_list), on="CLNT_NO", how="inner")

print(f"Records matching our client list: {client_campaigns.count()}")


# %% Cell: Summary by MNE
summary = client_campaigns.groupBy("MNE").agg(
    F.countDistinct("CLNT_NO").alias("UNIQUE_CLIENTS"),
    F.count("*").alias("TOTAL_TIMES_TARGETED")
).orderBy("TOTAL_TIMES_TARGETED", ascending=False)

summary.show(100, truncate=False)


# %% Cell: Overall Stats
total_clients = client_list.count()
clients_in_any_campaign = client_campaigns.select("CLNT_NO").distinct().count()

print(f"Total clients in list: {total_clients}")
print(f"Clients targeted by ANY campaign: {clients_in_any_campaign} ({round(clients_in_any_campaign/total_clients*100, 1)}%)")
print(f"Clients NOT targeted: {total_clients - clients_in_any_campaign}")
That's it. Simple summary of MNE vs count. Is this what you want?